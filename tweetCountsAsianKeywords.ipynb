{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import json_normalize\n",
    "import pip._vendor.requests \n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import csv\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# To get bearer token environment variable\n",
    "bearer_token = os.environ.get(\"BEARER-TOKEN\")\n",
    "\n",
    "search_url = \"https://api.twitter.com/2/tweets/counts/all\"\n",
    "\n",
    "# Optional params: start_time,end_time,since_id,until_id,next_token,granularity\n",
    "\n",
    "def query_params(next_token):\n",
    "\n",
    "    return {'query': '(asian OR asian indian OR asians OR asiatic OR azn OR brunei OR bruneian OR burma OR burmese OR cambodia OR cambodian OR china OR chinaman OR chinese OR ching chong OR chink OR chinkerbell OR chinks OR cracker jap OR dog eater OR east asian OR east timor OR far eastern OR filipino OR filipinos OR gook OR hong kong OR indonesia OR indonesian OR japan OR japanese OR korean OR koreans OR lao OR laos OR laotian OR macao OR macau OR malaysia OR malaysian OR mongolia OR mongolian OR mongolians OR myanmar OR north korea OR north korean OR oriental OR orientals OR philippines OR singapore OR singaporean OR slant eyed OR south korea OR south korean OR southeast asian OR soyback OR squint nigger OR taiwan OR taiwanese OR thai OR thailand OR tibet OR tibetan OR timorese OR vietnam OR vietnamese) lang:en -is:retweet place_country:gb', 'granularity': 'day', 'start_time': '2022-01-01T00:00:00Z', 'end_time': '2022-06-01T00:00:00Z', 'next_token': next_token}\n",
    "\n",
    "    \n",
    "def bearer_oauth(r):\n",
    "    \"\"\"\n",
    "    Method required by bearer token authentication.\n",
    "    \"\"\"\n",
    "\n",
    "    r.headers[\"Authorization\"] = f\"Bearer {bearer_token}\"\n",
    "    r.headers[\"User-Agent\"] = \"v2FullArchiveTweetCountsPython\"\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_endpoint(url, params):\n",
    "    response = pip._vendor.requests.request(\"GET\", search_url, auth=bearer_oauth, params=params)\n",
    "    # print(response.status_code)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "    return response.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweet_counts():\n",
    "    next_token = {}\n",
    "    finished = False\n",
    "    while finished == False:\n",
    "        json_response = connect_to_endpoint(search_url, query_params(next_token))\n",
    "        print(json_response)\n",
    "        if 'next_token' in json_response['meta']:\n",
    "            # Save the token to use for next call\n",
    "            next_token = json_response['meta']['next_token']\n",
    "        else:\n",
    "            finished = True\n",
    "    return json_response\n",
    "\n",
    "\n",
    "get_tweet_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweet_counts_to_CSV():\n",
    "    # using mode \"w+\"\" to truncate the file, if simply want to update (add more rows to) the file use mode \"a\"\n",
    "    csvFile = open(\"tweetCountsAsianKeywords.csv\", \"w+\", newline = \"\", encoding = \"utf-8\")\n",
    "    csvWriter = csv.writer(csvFile)\n",
    "\n",
    "    #creating headers\n",
    "    csvWriter.writerow(['start', 'tweet count'])\n",
    "\n",
    "    next_token = {}\n",
    "    finished = False\n",
    "   \n",
    "    while finished == False:\n",
    "        json_response = connect_to_endpoint(search_url, query_params(next_token))\n",
    "        # print(json_response)\n",
    "        for r in json_response['data']:\n",
    "            start = r['start']\n",
    "            count = r['tweet_count']\n",
    "            result = [start, count]\n",
    "            csvWriter.writerow(result)\n",
    "            \n",
    "        if 'next_token' in json_response['meta']:\n",
    "            # Save the token to use for next call\n",
    "            next_token = json_response['meta']['next_token']\n",
    "        else:\n",
    "            finished = True\n",
    "    csvFile.close()\n",
    "\n",
    "\n",
    "get_tweet_counts_to_CSV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tweetCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01 00:00:00+00:00</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-02 00:00:00+00:00</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-03 00:00:00+00:00</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-04 00:00:00+00:00</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-05 00:00:00+00:00</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>2022-05-27 00:00:00+00:00</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>2022-05-28 00:00:00+00:00</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>2022-05-29 00:00:00+00:00</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>2022-05-30 00:00:00+00:00</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>2022-05-31 00:00:00+00:00</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         date  tweetCount\n",
       "0   2022-01-01 00:00:00+00:00         223\n",
       "1   2022-01-02 00:00:00+00:00         210\n",
       "2   2022-01-03 00:00:00+00:00         219\n",
       "3   2022-01-04 00:00:00+00:00         209\n",
       "4   2022-01-05 00:00:00+00:00         199\n",
       "..                        ...         ...\n",
       "146 2022-05-27 00:00:00+00:00         184\n",
       "147 2022-05-28 00:00:00+00:00         185\n",
       "148 2022-05-29 00:00:00+00:00         183\n",
       "149 2022-05-30 00:00:00+00:00         198\n",
       "150 2022-05-31 00:00:00+00:00         188\n",
       "\n",
       "[151 rows x 2 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_tweet_counts_to_df():\n",
    "    next_token = {}\n",
    "    finished = False\n",
    "    data = []\n",
    "   \n",
    "    while finished == False:\n",
    "        json_response = connect_to_endpoint(search_url, query_params(next_token))\n",
    "        # print(json_response)\n",
    "        for r in json_response['data']:\n",
    "            start = r['start']\n",
    "            count = r['tweet_count']\n",
    "            startDate = datetime.strptime(start, '%Y-%m-%dT%H:%M:%S.%f%z')\n",
    "            result = [startDate, count]\n",
    "            data.append(result)\n",
    "            \n",
    "        if 'next_token' in json_response['meta']:\n",
    "            # Save the token to use for next call\n",
    "            next_token = json_response['meta']['next_token']\n",
    "        else:\n",
    "            finished = True\n",
    "    \n",
    "    sortedData = sorted(data, key=itemgetter(0))\n",
    "\n",
    "    df = pd.DataFrame(sortedData, columns=['date', 'tweetCount'])\n",
    "    return df\n",
    "\n",
    "get_tweet_counts_to_df()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b04001ca54e5ffc9c42d9fa47127f5c745705fc157c2151e145f1f4ee061d594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
